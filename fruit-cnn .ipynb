{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nprint(\"/kaggle/inputfruits/fruits-360_dataset/fruits-360/Training/\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-09T10:17:19.784121Z","iopub.execute_input":"2022-08-09T10:17:19.785128Z","iopub.status.idle":"2022-08-09T10:17:19.819027Z","shell.execute_reply.started":"2022-08-09T10:17:19.785040Z","shell.execute_reply":"2022-08-09T10:17:19.817477Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport zipfile\nimport pathlib\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nimport os\nfrom skimage.transform import resize\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import Sequential\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:17:22.278132Z","iopub.execute_input":"2022-08-09T10:17:22.281811Z","iopub.status.idle":"2022-08-09T10:17:30.467904Z","shell.execute_reply.started":"2022-08-09T10:17:22.281736Z","shell.execute_reply":"2022-08-09T10:17:30.466517Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training/\"\ntest_dir = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/\"","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:19:52.287360Z","iopub.execute_input":"2022-08-09T10:19:52.288174Z","iopub.status.idle":"2022-08-09T10:19:52.295089Z","shell.execute_reply.started":"2022-08-09T10:19:52.288130Z","shell.execute_reply":"2022-08-09T10:19:52.293501Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Get class names\nimport pathlib\ndata_dir = pathlib.Path(train_dir)\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nprint(class_names,len(class_names))","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:19:53.874239Z","iopub.execute_input":"2022-08-09T10:19:53.874665Z","iopub.status.idle":"2022-08-09T10:19:53.929589Z","shell.execute_reply.started":"2022-08-09T10:19:53.874635Z","shell.execute_reply":"2022-08-09T10:19:53.928278Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Get class names\nimport pathlib\ndata_dir = pathlib.Path(test_dir)\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nprint(class_names,len(class_names))","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:19:56.869867Z","iopub.execute_input":"2022-08-09T10:19:56.870372Z","iopub.status.idle":"2022-08-09T10:19:56.921196Z","shell.execute_reply.started":"2022-08-09T10:19:56.870319Z","shell.execute_reply":"2022-08-09T10:19:56.919768Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sel = random.sample(list(class_names),10)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:20:04.472504Z","iopub.execute_input":"2022-08-09T10:20:04.472938Z","iopub.status.idle":"2022-08-09T10:20:04.480902Z","shell.execute_reply.started":"2022-08-09T10:20:04.472894Z","shell.execute_reply":"2022-08-09T10:20:04.478589Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Visualize\ndef view_random_image(target_dir,target_class):\n  target_folder = target_dir+\"/\"+target_class\n  random_image = random.sample(os.listdir(target_folder),1) # This will be returned as a list, so we use [0] below\n  img = mpimg.imread(target_folder+\"/\"+random_image[0])\n  fig = plt.imshow(img)\n  plt.title(target_class)\n  # plt.axes('off')\n  fig.axes.get_xaxis().set_visible(False)\n  fig.axes.get_yaxis().set_visible(False)  \n  print(\"Image shape:\",img.shape)\n  return img","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:20:10.461522Z","iopub.execute_input":"2022-08-09T10:20:10.462321Z","iopub.status.idle":"2022-08-09T10:20:10.471962Z","shell.execute_reply.started":"2022-08-09T10:20:10.462285Z","shell.execute_reply":"2022-08-09T10:20:10.470197Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"img = view_random_image(train_dir,\"Apple Golden 3\")","metadata":{"execution":{"iopub.status.busy":"2022-08-08T05:05:55.382089Z","iopub.execute_input":"2022-08-08T05:05:55.383029Z","iopub.status.idle":"2022-08-08T05:05:55.696475Z","shell.execute_reply.started":"2022-08-08T05:05:55.382977Z","shell.execute_reply":"2022-08-08T05:05:55.695477Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255.)\ntest_datagen = ImageDataGenerator(rescale=1/255.)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:20:14.218720Z","iopub.execute_input":"2022-08-09T10:20:14.219565Z","iopub.status.idle":"2022-08-09T10:20:14.226740Z","shell.execute_reply.started":"2022-08-09T10:20:14.219533Z","shell.execute_reply":"2022-08-09T10:20:14.225235Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data = train_datagen.flow_from_directory(directory=train_dir,\n                                               target_size =(224,224),\n                                               batch_size=256,\n                                               class_mode=\"categorical\",\n                                              classes=sel)\ntest_data = test_datagen.flow_from_directory(directory=test_dir,\n                                             target_size=(224,224),\n                                             batch_size=256,\n                                             class_mode=\"categorical\",\n                                            classes=sel)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:20:16.888007Z","iopub.execute_input":"2022-08-09T10:20:16.888420Z","iopub.status.idle":"2022-08-09T10:20:18.717415Z","shell.execute_reply.started":"2022-08-09T10:20:16.888389Z","shell.execute_reply":"2022-08-09T10:20:18.716010Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(train_data),len(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:20:20.726010Z","iopub.execute_input":"2022-08-09T10:20:20.726451Z","iopub.status.idle":"2022-08-09T10:20:20.736034Z","shell.execute_reply.started":"2022-08-09T10:20:20.726420Z","shell.execute_reply":"2022-08-09T10:20:20.734267Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Building the model\nm1 = Sequential([\n    Conv2D(filters=8,kernel_size=5,input_shape=(224,224,3),activation=\"relu\"),\n    MaxPool2D(),\n\n    Conv2D(filters=16,kernel_size=4,activation=\"relu\"),\n    MaxPool2D(),\n\n    Conv2D(filters=32,kernel_size=3,activation=\"relu\"),\n    tf.keras.layers.GlobalAveragePooling2D(),\n\n    Flatten(),\n    Dense(10,activation=\"softmax\")\n])\nm1.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=Adam(learning_rate=0.01),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:17:36.546539Z","iopub.execute_input":"2022-08-09T10:17:36.547266Z","iopub.status.idle":"2022-08-09T10:17:40.557028Z","shell.execute_reply.started":"2022-08-09T10:17:36.547234Z","shell.execute_reply":"2022-08-09T10:17:40.554386Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import visualkeras as vk","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:18:55.436133Z","iopub.execute_input":"2022-08-09T10:18:55.436629Z","iopub.status.idle":"2022-08-09T10:18:55.475758Z","shell.execute_reply.started":"2022-08-09T10:18:55.436576Z","shell.execute_reply":"2022-08-09T10:18:55.474458Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"vk.layered_view(m1)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:19:09.028779Z","iopub.execute_input":"2022-08-09T10:19:09.029414Z","iopub.status.idle":"2022-08-09T10:19:09.106293Z","shell.execute_reply.started":"2022-08-09T10:19:09.029381Z","shell.execute_reply":"2022-08-09T10:19:09.104737Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"h1 = m1.fit(\n    train_data,epochs=5,\n    validation_data=test_data,\n    steps_per_epoch=len(train_data),\n    validation_steps=len(test_data)\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T05:13:21.950747Z","iopub.execute_input":"2022-08-08T05:13:21.951115Z","iopub.status.idle":"2022-08-08T05:15:04.778377Z","shell.execute_reply.started":"2022-08-08T05:13:21.951083Z","shell.execute_reply":"2022-08-08T05:15:04.777200Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(h1.history).plot()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T05:15:19.782148Z","iopub.execute_input":"2022-08-08T05:15:19.782741Z","iopub.status.idle":"2022-08-08T05:15:20.066728Z","shell.execute_reply.started":"2022-08-08T05:15:19.782698Z","shell.execute_reply":"2022-08-08T05:15:20.065764Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Model 2 will have the architecture given below\n![](https://www.researchgate.net/profile/Jose-Naranjo-Torres/publication/341455419/figure/fig3/AS:892525732712453@1589806125572/Designed-CNN-architecture-for-fruit-classification.png)","metadata":{}},{"cell_type":"code","source":"# Let us try changing batch size and try with more change in model architecture\ntrain_data = train_datagen.flow_from_directory(directory=train_dir,\n                                               target_size =(224,224),\n                                               batch_size=512,\n                                               class_mode=\"categorical\",\n                                              classes=sel)\ntest_data = test_datagen.flow_from_directory(directory=test_dir,\n                                             target_size=(224,224),\n                                             batch_size=512,\n                                             class_mode=\"categorical\",\n                                            classes=sel)\nm2 = Sequential([\n    Conv2D(filters=8,kernel_size=5,input_shape=(224,224,3),activation=\"relu\"),\n    tf.keras.layers.Normalization(),\n    MaxPool2D(),\n\n    Conv2D(filters=16,kernel_size=4,activation=\"relu\"),\n    tf.keras.layers.Normalization(),\n    MaxPool2D(),\n\n    Conv2D(filters=32,kernel_size=3,activation=\"relu\"),\n    tf.keras.layers.GlobalAveragePooling2D(),\n\n    Flatten(),\n    Dense(10,activation=\"softmax\")\n])\nm2.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=Adam(learning_rate=0.01),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:21:51.247254Z","iopub.execute_input":"2022-08-09T10:21:51.247708Z","iopub.status.idle":"2022-08-09T10:21:51.668104Z","shell.execute_reply.started":"2022-08-09T10:21:51.247652Z","shell.execute_reply":"2022-08-09T10:21:51.666750Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"vk.layered_view(m2)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:22:01.543469Z","iopub.execute_input":"2022-08-09T10:22:01.543919Z","iopub.status.idle":"2022-08-09T10:22:01.612506Z","shell.execute_reply.started":"2022-08-09T10:22:01.543888Z","shell.execute_reply":"2022-08-09T10:22:01.610862Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"h2 = m2.fit(\n    train_data,epochs=10,\n    validation_data=test_data,\n    steps_per_epoch=len(train_data),\n    validation_steps=len(test_data)\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T05:18:33.375768Z","iopub.execute_input":"2022-08-08T05:18:33.376155Z","iopub.status.idle":"2022-08-08T05:21:09.998409Z","shell.execute_reply.started":"2022-08-08T05:18:33.376122Z","shell.execute_reply":"2022-08-08T05:21:09.997473Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Finally the model has reached above 90 accuracy scores ðŸ˜‡ðŸ˜‡ðŸ˜‡\npd.DataFrame(h2.history).plot()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T05:22:31.071158Z","iopub.execute_input":"2022-08-08T05:22:31.071638Z","iopub.status.idle":"2022-08-08T05:22:31.292455Z","shell.execute_reply.started":"2022-08-08T05:22:31.071596Z","shell.execute_reply":"2022-08-08T05:22:31.291517Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Let us try to make VGG16 architecture with change in output layer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/0*0M8CobXpNwFDCmOQ)","metadata":{}},{"cell_type":"code","source":"vgg16 = Sequential([\n    Conv2D(64,kernel_size=3,input_shape=(224,224,3),activation=\"relu\",padding=\"same\"),\n    Conv2D(64,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(128,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(128,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(256,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(256,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(256,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(512,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(512,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(512,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(512,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(512,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(512,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Flatten(),\n    Dense(256,activation=\"relu\",name=\"fc1\"),\n    Dense(128,activation=\"relu\",name=\"fc2\"),\n    Dense(10,activation=\"softmax\",name=\"output\")\n])\nvgg16.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=Adam(learning_rate=0.001),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:32:07.961177Z","iopub.execute_input":"2022-08-09T10:32:07.961613Z","iopub.status.idle":"2022-08-09T10:32:08.152884Z","shell.execute_reply.started":"2022-08-09T10:32:07.961560Z","shell.execute_reply":"2022-08-09T10:32:08.151531Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"vk.layered_view(vgg16,legend=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:32:28.742272Z","iopub.execute_input":"2022-08-09T10:32:28.742801Z","iopub.status.idle":"2022-08-09T10:32:29.154403Z","shell.execute_reply.started":"2022-08-09T10:32:28.742760Z","shell.execute_reply":"2022-08-09T10:32:29.152842Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# h_vgg16 = vgg16.fit(\n#     train_data,epochs=5,\n#     validation_data=test_data,\n#     steps_per_epoch=len(train_data),\n#     validation_steps=len(test_data)\n# )\n# The notebook crashes if we try to train VGG16. I will have to use transfer learning for this.","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:48:20.697103Z","iopub.execute_input":"2022-08-09T10:48:20.698318Z","iopub.status.idle":"2022-08-09T10:48:20.704595Z","shell.execute_reply.started":"2022-08-09T10:48:20.698286Z","shell.execute_reply":"2022-08-09T10:48:20.703207Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Let us try a model similar to VGG but with less filters\nvgg16_changed = Sequential([\n    Conv2D(4,kernel_size=3,input_shape=(224,224,3),activation=\"relu\",padding=\"same\"),\n    Conv2D(4,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(8,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(8,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(16,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(16,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(32,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(32,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Conv2D(16,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    Conv2D(16,kernel_size=3,padding=\"same\",activation=\"relu\"),\n    MaxPool2D(pool_size=2,strides=2),\n    \n    Flatten(),\n    Dense(10,activation=\"softmax\",name=\"output\")\n])\nvgg16_changed.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer=Adam(learning_rate=0.001),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:54:37.155615Z","iopub.execute_input":"2022-08-09T10:54:37.156133Z","iopub.status.idle":"2022-08-09T10:54:37.295291Z","shell.execute_reply.started":"2022-08-09T10:54:37.156085Z","shell.execute_reply":"2022-08-09T10:54:37.293980Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"vk.layered_view(vgg16_changed,legend=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:55:01.889577Z","iopub.execute_input":"2022-08-09T10:55:01.890033Z","iopub.status.idle":"2022-08-09T10:55:01.999587Z","shell.execute_reply.started":"2022-08-09T10:55:01.890003Z","shell.execute_reply":"2022-08-09T10:55:01.998411Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"vgg16_changed = vgg16_changed.fit(\n    train_data,epochs=10,\n    validation_data=test_data,\n    steps_per_epoch=len(train_data),\n    validation_steps=len(test_data)\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T10:55:35.456069Z","iopub.execute_input":"2022-08-09T10:55:35.456495Z","iopub.status.idle":"2022-08-09T10:59:25.606335Z","shell.execute_reply.started":"2022-08-09T10:55:35.456465Z","shell.execute_reply":"2022-08-09T10:59:25.604972Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# That's amazing, this changed VGG16 worked even better than my previous models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(vgg16_changed.history).plot()\n# That's great !!","metadata":{"execution":{"iopub.status.busy":"2022-08-09T11:00:01.306238Z","iopub.execute_input":"2022-08-09T11:00:01.307507Z","iopub.status.idle":"2022-08-09T11:00:01.587141Z","shell.execute_reply.started":"2022-08-09T11:00:01.307459Z","shell.execute_reply":"2022-08-09T11:00:01.585978Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}